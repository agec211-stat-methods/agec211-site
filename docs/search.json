[
  {
    "objectID": "m7-regression.html",
    "href": "m7-regression.html",
    "title": "Tests on means",
    "section": "",
    "text": "Introduction to linear regression\nModel estimation and interpretation\nDetecting and handling multicollinearity\nRegression diagnostics\n\nView slides in new window\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts"
  },
  {
    "objectID": "m5-tests-on-means.html",
    "href": "m5-tests-on-means.html",
    "title": "Tests on means",
    "section": "",
    "text": "Introduction to hypothesis testisng\nParametric vs non-parametric tests\nIndependent sample t-tests\nPaired sample t-test\nOne-way ANOVA\nChi-square test\n\nView slides in new window\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts"
  },
  {
    "objectID": "m3-reproducible-report.html",
    "href": "m3-reproducible-report.html",
    "title": "Reproducible report with Quarto in R",
    "section": "",
    "text": "Introduction to Quarto\nQuarto document elements\nExercise: generating reports\nImproving report\n\nView slides in new window\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts"
  },
  {
    "objectID": "m1-intro-r.html",
    "href": "m1-intro-r.html",
    "title": "Intro to R programming",
    "section": "",
    "text": "R objects\nR packages\nReading data in R\nBasic data wrangling\nView slides in new window",
    "crumbs": [
      "Topics",
      "Module 1: Intro to R programming"
    ]
  },
  {
    "objectID": "m1-intro-r.html#exercises",
    "href": "m1-intro-r.html#exercises",
    "title": "Intro to R programming",
    "section": "Exercises",
    "text": "Exercises\n\nInstall R and RStudio on your computer.\nDownload the entire folder 00-module-intro-r from the Google Drive link. For the meantime, keep the folder in your computer and wait for further instructions during the class.\nBefore the class start, open the RStudio and paste the following code in the console to install the required packages. Just click the clipboard icon to copy the code.\n\n\n## install required packages\ninstall.packages(c(\"janitor\", \"readxl\", \"haven\", \"tidyverse\", \"skimr\"))\n\n\n\n\n\n\n\nImportant\n\n\n\nPlease make sure to install the required packages before the class starts, as we may not have a secure internet connection. If you encounter any issues, please let me know.",
    "crumbs": [
      "Topics",
      "Module 1: Intro to R programming"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AgEc 211: Statistical Methods",
    "section": "",
    "text": "Class schedule: TBA  Instructor: Christopher Llones  e-mail: christopher.llones@vsu.edu.ph  Pre-requisites: Basic statistics or COI  Course credits: 3 units \n\n\nCourse description\nApplication of statistical concept and tools in analyzing economic phenomena.\n\n\nCourse objectives\n\nPerform basic operation using R programming as the main statistical software\nDemonstrate how to conduct descriptive analysis using statistical software and check necessary assumptions\nDemonstrate how to conduct descriptive analysis using stistical\nConduct parametric and non-parametric tests\nTest economic relationship using correlation / regression approach using appropriate statistical software and interpret results\nApply appropriate statistical methods to investigate actual economic problems.\n\n\n\nCourse outline\n\n\n\n\n\n\n\n\nTopics\nLessons\nDescription\n\n\n\n\nModule 1: Introduction to R Programming\n\nInstalling R and RStudio\nR Basics\nWorking with R scripts\nImporting data\nBasic data wrangling\n\n\nLearn to install and configure R and RStudio.\nUnderstand and apply basic R syntax including data types, vectors, and data frames.\nDevelop proficiency in writing, saving, and executing R scripts.\nImport dataset and prepare them for analysis.\nClean and transform data .\n\n\n\nModule 2: Introduction to data visualization using ggplot2\n\nUnderstanding grammar of graphics\nDataset and mapping\nGeometries\nStatistical transformation and plotting distribution\nPosition adjustment and scales\n\n\nUnderstand the grammar of graphics and its role in structuring visualizations.\nCreate and customize basic plots including histograms, bar charts, boxplots, and scatterplot.\nMap variables to visual aesthetics such as color, shape, and size to enhance interpretability.\nApply faceting techniques to produce multi-panel plots for comparative analysis.\nModify plot themes and coordinate systems to improve clarity and accessibility.\nExport visualizations for use in reports, presentations, policy briefs, and others.\n\n\n\nModule 3: Reproducible report with Quarto in R\n\nIntroduction to Quarto\nCreating Quarto document\nEmbedding R code\nFormatting Outputs\nExporting reports\n\n\nLearn to create dynamic, reproducible documents using Quarto and markdown syntax.\nEmbed R code and inline calculations within narrative text to integrate analysis and interpretation.\nFormat outputs such as tables and plots for professional presentation.\nRender reports to multiple formats including HTML, PDF, and Word for diverse audiences.\nDevelop the ability to produce transparent, replicable research outputs for academic and policy contexts.\n\n\n\nModule 4: survey research design\n\nMethods of data collection\nSampling design in surveys\nMeasurement issues in survey research\nQuestionnaire construction\nBasics of interviewing\nCreating a codebook\nData entry\n\n\nDiscuss the various methods of data collection including survey, observation and experimental methods.\nDiscuss different ways for gathering a sample; random and non-random sampling. Discuss rudimentary formulas for sample size calculation.\nDiscuss the issues in assigning numbers to represent quantities of attributes. Discuss the various scales of measurement. Discuss criteria in constructing good measurement of variables: reliablity and validity.\nDiscuss the various advantages and disadvantages of interviews and questionnaire over other methods of data collection.\nDiscuss the do’s and dont’s of an interviewer’s conduct.\nDiscuss the importance of creating a codebook for survey data.\nDiscuss rudimentary of data entry.\n\n\n\nModule 5: exploratory data analysis\n\nRudiments of EDA\nCharts and tables\nMeasures of central tendency\nDispersion, parameters, skewness and kurtosis\nContingency tables and scatter plot\n\n\nDiscuss EDA as the first step in data analysis.\nDiscuss various techniques in summarizing and visualizing data.\nDiscuss the various measures of central tendency and data location.\nDiscuss the relevance of various dispersion, parameters, skewness and kurtosis.\nDiscuss the relevance of contingency tables and scatterplots for summarizing and visualizing data.\n\n\n\nModule 6: test on means\n\nParametric test on means\nNon-parametric test on means\n\n\nDiscuss the various t-tests and ANOVA and perform them on a sample data with R.\nPerform various non-parametric equivalent of the t-tests and ANOVA on sample data with R.\n\n\n\nModule 7: correlation and regression analysis\n\nCorrelation analysis\nReview of Regression analysis\n\n\nDiscuss the various types of correlation analysis procedures. Interpret the correlation coefficient.\nDiscuss the various aspects of regression model building.\n\n\n\nModule 8: limited-dependent variable models\n\nReview of binary dependent regression\nExtension to the logit model.\nCensored and truncated regression models.\nCount dependent variable models.\n\n\nDiscuss the various aspects of the logit and probit.\nDiscuss the multinomial and ordinal logit models.\nDiscuss the Tobit regression model for censored data and truncated regression models.\nDiscuss Poisson and Negative Binomial regression models in the regression analysis of count-dependent variable models.\n\n\n\nModule 9: multivariate statistical analysis\n\nCluster analysis\nPrincipal component analysis\nExploratory factor analysis\nConfirmatory factor anlysis\nStructural equation modelling\n\n\nUnderstand and apply different clustering methods. Analyze and evaluate the quality and effectiveness of different clusters in dataset.\nLearn to perform and interpret principal component analysis to reduce the dimensionality of dataset. Develop the ability to identify and retain significant components for simplifying data without losing critical information.\nIdentify and estimate underlying factor structures within a set of observed variables.\nUnderstand model-based factor anlaysis and develop proficiency in evaluating model fit and making necessary adjustments to improve analysis.\nApply SEM techniques to understand relationships among variables and construct theoretical models.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "01-assignment-1-netflix-data.html",
    "href": "01-assignment-1-netflix-data.html",
    "title": "AgEc 211",
    "section": "",
    "text": "Course Title: Agec211: Statistical methods  Instructor: Christopher Llones  Assignment: Netflix Dataset Analysis in R  Due Date: 9 October 2025",
    "crumbs": [
      "Topics",
      "Module 1 assignment"
    ]
  },
  {
    "objectID": "01-assignment-1-netflix-data.html#objective",
    "href": "01-assignment-1-netflix-data.html#objective",
    "title": "AgEc 211",
    "section": "Objective",
    "text": "Objective\nThis assignment will assess your ability to apply R programming skills—specifically using the dplyr package and the pipe operator (%&gt;%)—to explore and analyze a real-world dataset. You will work with the Netflix Movies & TV Shows dataset to answer questions using code.",
    "crumbs": [
      "Topics",
      "Module 1 assignment"
    ]
  },
  {
    "objectID": "01-assignment-1-netflix-data.html#instructions",
    "href": "01-assignment-1-netflix-data.html#instructions",
    "title": "AgEc 211",
    "section": "Instructions",
    "text": "Instructions\n\nUse R and the dplyr package to answer each question.\nSubmit your R script file (.R) with your code and outputs.\nUse the pipe operator (%&gt;%) for all data manipulations.\nYou may use additional packages like tidyr or stringr if needed.\nEnsure your code is clean, commented, and reproducible.\n\n\n\n\n\n\n\nDataset and files\n\n\n\n\nAccess the dataset and R script template from the agec211-assignment1 folder.\nSubmit your completed R script file (.R) by the due date and upload using this link: Submission Link.",
    "crumbs": [
      "Topics",
      "Module 1 assignment"
    ]
  },
  {
    "objectID": "01-assignment-1-netflix-data.html#questions",
    "href": "01-assignment-1-netflix-data.html#questions",
    "title": "AgEc 211",
    "section": "Questions",
    "text": "Questions\nPart 1: Data exploration\n\nHow many rows and columns are in the dataset?\nList all unique types of content (e.g., Movie, TV Show).\nHow many titles were released in 2020?\n\nPart 2: filtering and summarising\n\nFilter the dataset to show only TV Shows released in India. How many are there?\nFind the top 5 most common ratings.\nWhich year had the most titles added to Netflix?\n\nPart 3: grouping and aggregation\n\nGroup the data by type and count how many entries each type has.\nGroup the data by release_year and summarize the number of titles released per year.\nWhich country has produced the most content on Netflix?\n\nAdvanced Filtering\n\nFilter the dataset to show all Movies with a duration longer than 100 minutes.\nFind all titles directed by ‘Steven Spielberg’.\nList all titles with the genre containing ‘Documentary’.\n\nBonus Challenge\n\nCreate a new column that extracts the number of seasons for TV Shows. Then, find the average number of seasons.\nWhich actor appears most frequently across all titles?",
    "crumbs": [
      "Topics",
      "Module 1 assignment"
    ]
  },
  {
    "objectID": "01-assignment-1-netflix-data.html#grading-rubrics",
    "href": "01-assignment-1-netflix-data.html#grading-rubrics",
    "title": "AgEc 211",
    "section": "Grading rubrics",
    "text": "Grading rubrics\n\n\n\n\n\n\n\n\n\n\nCriteria\nExcellent (5pts)\nGood (4pts)\nFair (2-3 pts)\nNeeds improvement (0-1 pt)\n\n\n\n\nCode accuracy\nAll answers are correct and match expected outputs.\nMost answers are correct with minor errors.\nSeveral answers are incorrect or incomplete.\nMany answers are missing or incorrect.\n\n\nUse of dplyr Functions\nConsistently uses appropriate dplyr verbs (filter, mutate, summarise, etc.).\nUses dplyr functions correctly in most cases.\nUses some dplyr functions but inconsistently or incorrectly.\nRarely uses dplyr or misuses functions.\n\n\nPipe Operator Usage (%&gt;%)\nPipe operator is used fluently and correctly throughout.\nMostly correct usage with occasional syntax issues.\nUsed sporadically or with frequent errors.\nNot used or used incorrectly.\n\n\nData Manipulation & Filtering\nDemonstrates strong understanding of filtering, grouping, and summarizing.\nShows good grasp with minor gaps.\nBasic filtering and grouping attempted but lacks depth.\nLittle to no meaningful data manipulation.\n\n\nInsight & Interpretation\nProvides thoughtful insights or observations where applicable.\nSome interpretation is present.\nMinimal interpretation or unclear reasoning.\nNo interpretation or irrelevant commentary.\n\n\nBonus Challenge (Q13–Q14)\nCompleted with correct logic and creative approach.\nAttempted with mostly correct logic.\nAttempted but contains errors or lacks clarity.\nNot attempted or incorrect.\n\n\nReproducibility\nCode runs without errors and produces expected results.\nMinor issues but generally reproducible.\nSome errors prevent full reproducibility.\nCode fails to run or produces major errors.",
    "crumbs": [
      "Topics",
      "Module 1 assignment"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "m0-agec211-project.html#instructions",
    "href": "m0-agec211-project.html#instructions",
    "title": "AgEc 211",
    "section": "Instructions",
    "text": "Instructions\nWelcome to the midterm project exercise! In this exercise, you will work on a project that involves analyzing employee attrition and performance using the HR Analytics Employee Attrition & Performance dataset. The primary goal is to develop insights into the factors that contribute to employee attrition and provide recommendations for HR interventions that could help reduce attrition and improve overall employee satisfaction and performance.\nDownload the project files using this link: Midterm project files. Be sure to download the entire folder agec211-project-exercise. The project files include the dataset and a template Quarto markdown file that you will use to complete the exercise.\nFirst, rename the lastname-firstname.qmd file to your actual last name and first name. For example, if your name is John Doe, the file should be named doe-john.qmd. Afterward, open the R project 20241224-agec211-project-exercise.Rproj by double-clicking the file and render the Quarto markdown file to generate the HTML file."
  },
  {
    "objectID": "m0-agec211-project.html#project-overiew",
    "href": "m0-agec211-project.html#project-overiew",
    "title": "AgEc 211",
    "section": "Project overiew",
    "text": "Project overiew\nIn this project, we will explore employee attrition and performance using the HR Analytics Employee Attrition & Performance dataset. The primary goal is to develop insights into the factors that contribute to employee attrition.\nThe dataset used for this project provides information about employee demographics, performance metrics, and various satisfaction ratings. By analyzing a range of factors, including demographic data, job satisfaction, work-life balance, and job role, we aim to help businesses identify key areas where they can improve employee retention.\n\n## datatable function from DT package create an HTML widget display of the dataset\n## install DT package if the package is not yet available in your R environment\nreadxl::read_excel(\"dataset/dataset-variable-description.xlsx\") |&gt; \n  DT::datatable()"
  },
  {
    "objectID": "m0-agec211-project.html#data-wrangling-and-management",
    "href": "m0-agec211-project.html#data-wrangling-and-management",
    "title": "AgEc 211",
    "section": "Data wrangling and management",
    "text": "Data wrangling and management\n\nLibraries\n\n\n\n\n\n\nTask: Load the necessary libraries\n\n\n\nBefore we start working on the dataset, we need to load the necessary libraries that will be used for data wrangling, analysis and visualization. Make sure to load the following libraries here. For packages to be installed, you can use the install.packages function. There are packages to be installed later on this project, so make sure to install them as needed and load them here.\n\n\n\n# load all your libraries here\n\n\n\nData importation\n\n\n\n\n\n\nTask 2.1. Merging dataset\n\n\n\n\nImport the two dataset Employee.csv and PerformanceRating.csv. Save the Employee.csv as employee_dta and PerformanceRating.csv as perf_rating_dta.\nMerge the two dataset using the left_join function from dplyr. Use the EmployeeID variable as the varible to join by. You may read more information about the left_join function here.\nSave the merged dataset as hr_perf_dta and display the dataset using the datatable function from DT package.\n\n\n\n\n## import the two data here\n\n\n## merge employee_dta and perf_rating_dta using left_join function.\n## save the merged dataset as hr_perf_dta\n\n\n\n## Use the datatable from DT package to display the merged dataset\n\n\n\nData management\n\n\n\n\n\n\nTask 2.2. Standardizing variable names\n\n\n\n\nUsing the clean_names function from janitor package, standardize the variable names by using the recommended naming of variables.\nSave the renamed variables as hr_perf_dta to update the dataset.\n\n\n\n\n## clean names using the janitor packages and save as hr_perf_dta\n\n\n## display the renamed hr_perf_dta using datatable function\n\n\n\n\n\n\n\nTask 2.3. Recode data entries\n\n\n\n\nCreate a new variable cat_education wherein education is 1 = No formal education; 2 = High school; 3 = Bachelor; 4 = Masters; 5 = Doctorate. Use the case_when function to accomplish this task.\nSimilarly, create new variables cat_envi_sat, cat_job_sat, and cat_relation_sat for environment_satisfaction, job_satisfaction, and relationship_satisfaction, respectively. Re-code the values accordingly as 1 = Very dissatisfied; 2 = Dissatisfied; 3 = Neutral; 4 = Satisfied; and 5 = Very satisfied.\nCreate new variables cat_work_life_balance, cat_self_rating, cat_manager_rating for work_life_balance, self_rating, and manager_rating, respectively. Re-code accordingly as 1 = Unacceptable; 2 = Needs improvement; 3 = Meets expectation; 4 = Exceeds expectation; and 5 = Above and beyond.\nCreate a new variable bi_attrition by transforming attrition variable as a numeric variabe. Re-code accordingly as No = 0, and Yes = 1.\nSave all the changes in the hr_perf_dta. Note that saving the changes with the same name will update the dataset with the new variables created.\n\n\n\n\n## create cat_education\n\n\n\n## create cat_envi_sat,  cat_job_sat, and cat_relation_sat\n\n\n\n\n## create cat_work_life_balance, cat_self_rating, and cat_manager_rating\n\n\n\n\n\n## create bi_attrition\n\n\n\n## print the updated hr_perf_dta using datatable function"
  },
  {
    "objectID": "m0-agec211-project.html#exploratory-data-analysis",
    "href": "m0-agec211-project.html#exploratory-data-analysis",
    "title": "AgEc 211",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nDescriptive statistics of employee attrition\n\n\n\n\n\n\nTask 3.1. Breakdown of attrition by key variables\n\n\n\n\nSelect the variables attrition, job_role, department, age, salary, job_satisfaction, and work_life_balance. Save as attrition_key_var_dta.\nCompute and plot the attrition rate across job_role, department, and age, salary, job_satisfaction, and work_life_balance. To compute for the attrition rate, group the dataset by job role. Afterward, you can use the count function to get the frequency of attrition for each job role and then divide it by the total number of observations. Save the computation as pct_attrition. Do not forget to ungroup before storing the output. Store the output as attrition_rate_job_role.\nPlot for the attrition rate across job_role has been done for you! Study each line of code. You have the freedom to customize your plot accordingly. Show your creativity!\n\n\n\n\n## selecting attrition key variables and save as `attrition_key_var_dta`\n\n\n\n\n## compute the attrition rate across job_role and save as attrition_rate_job_role\n\n\n\n## print attrition_rate_job_role\n\n\n## Plot the attrition rate\n\n\n\nAnalysis of compensation and turnover\n\n\n\n\n\n\nTask 3.2. Analyzing compensation and turnover\n\n\n\n\nCompare the average monthly income of employees who left the company (bi_attrition = 1) and those who stayed (bi_attrition = 0). Use the t.test function to conduct a t-test and determine if there is a significant difference in average monthly income between the two groups. Save the results in a variable called attrition_ttest_results.\nInstall the report package and use the report function to generate a report of the t-test results.\nInstall the ggstatsplot package and use the ggbetweenstats function to visualize the distribution of monthly income for employees who left and those who stayed. Make sure to map the bi_attrition variable to the x argument and the salary variable to the y argument.\nVisualize the salary variable for employees who left and those who stayed using geom_histogram with geom_freqpoly. Make sure to facet the plot by the bi_attrition variable and apply alpha on the histogram plot.\nProvide recommendations on whether revising compensation policies could be an effective retention strategy.\n\n\n\n\n## compare the average monthly income of employees who left and those who stayed\n\n\n\n\n## print the results of the t-test\n\n\n## install the report package and use the report function to generate a report of the t-test results\n\n\n# install ggstatsplot package and use ggbetweenstats function to visualize the distribution of monthly income for employees who left and those who stayed\n\n\n# create histogram and frequency polygon of salary for employees who left and those who stayed\n\n\n\n\n\n\n\nDiscussion:\n\n\n\nProvide your discussion here.\n\n\n\n\nEmployee satisfaction and performance analysis\n\n\n\n\n\n\nTask 3.3. Analyzing employee satisfaction and performance\n\n\n\n\nAnalyze the average performance ratings (both ManagerRating and SelfRating) of employees who left vs. those who stayed. Use the group_by and count functions to calculate the average performance ratings for each group.\nVisualize the distribution of SelfRating for employees who left and those who stayed using a bar plot. Use the ggplot function to create the plot and map the SelfRating variable to the x argument and the bi_attrition variable to the fill argument.\nSimilarly, visualize the distribution of ManagerRating for employees who left and those who stayed using a bar plot. Make sure to map the ManagerRating variable to the x argument and the bi_attrition variable to the fill argument.\nCreate a boxplot of salary by job_satisfaction and bi_attrition to analyze the relationship between salary, job satisfaction, and attrition. Use the geom_boxplot function to create the plot and map the salary variable to the x argument, the job_satisfaction variable to the y argument, and the bi_attrition variable to the fill argument. You need to transform the job_satisfaction and bi_attrition variables into factors before creating the plot or within the ggplot function.\nDiscuss the results of the analysis and provide recommendations for HR interventions based on the findings.\n\n\n\n\n# Analyze the average performance ratings (both ManagerRating and SelfRating) of employees who left vs. those who stayed.\n\n\n# Visualize the distribution of SelfRating for employees who left and those who stayed using a bar plot.\n\n\n# Visualize the distribution of ManagerRating for employees who left and those who stayed using a bar plot.\n\n\n# create a boxplot of salary by job_satisfaction and bi_attrition to analyze the relationship between salary, job satisfaction, and attrition.\n\n\n\n\n\n\n\nDiscussion:\n\n\n\nProvide your discussion here.\n\n\n\n\nWork-life balance and retention strategies\n\n\n\n\n\n\nTask 3.4. Analyzing work-life balance and retention strategies\n\n\n\nAt this point, you are already well aware of the dataset and the possible factors that contribute to employee attrition. Using your R skills, accomplish the following tasks:\n\nAnalyze the distribution of WorkLifeBalance ratings for employees who left versus those who stayed.\nUse visualizations to show the differences.\nAssess whether employees with poor work-life balance are more likely to leave.\n\nYou have the freedom how you will accomplish this task. Be creative and provide insights that will help HR develop effective retention strategies."
  },
  {
    "objectID": "m2-intro-dataviz.html",
    "href": "m2-intro-dataviz.html",
    "title": "Intro to data visualization using ggplot2",
    "section": "",
    "text": "The grammar of graphics\nDatasets and mapping\nGeometries\nStatistical transformation and plotting distribution\nPosition adjustment and scales\nCoordinates and themes\nFacets and custom plots\n\nView slides in new window\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts",
    "crumbs": [
      "Topics",
      "Module 2: Intro to data viz using ggplot2"
    ]
  },
  {
    "objectID": "m4-eda.html",
    "href": "m4-eda.html",
    "title": "Exploratory data analysis (EDA)",
    "section": "",
    "text": "Overview of EDA\nCentrality and variability\nAmounts and proportions\nComparisons\nTrends\n\nView slides in new window\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts"
  },
  {
    "objectID": "m6-correlations.html",
    "href": "m6-correlations.html",
    "title": "Correlations",
    "section": "",
    "text": "Understand concept of correlation\nCompute and interpret different correlation coefficient\nVisualize correlation pattern\nTest for statistical significance of correlation\n\nView slides in new window\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts"
  }
]